{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ba4040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import json\n",
    "from pandas import json_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f74e6a9",
   "metadata": {},
   "source": [
    "#2 Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5ed5a5",
   "metadata": {},
   "source": [
    "Before writing the code to webscrape a page, you'll want to inspect the HTML of the website. To do this, click on 'View' on the top of the screen, then 'Developer' -> 'Developer Tools'. The best way to understand the code that popped up on the screen, is to hover over different lines of the code and see what they highlight on the website itself. Another way you can explore, is by left-clicking and choosing 'Inspect' and look at the code brought to you. \n",
    "\n",
    "After exploring the website, you'll want to write the line \"(venv) $ python -m pip install requests\" into the terminal on your labtop. This allows us to read the HTML data into Python. \n",
    "\n",
    "In a Python notebook, first import the URL and use the function page = requests.get(\"Your_URL\"). The function retrieves the HTML data and puts it into an object that Python can read. \n",
    "\n",
    "By printing page.text(), a code similar to the HTML on the website will print. Unfortunately, this information itself is not super helpful. The tool we use to scrape websites is known as BeautifulSoup. So, we will import it into our notebook, as 'from bs4 import BeautifulSoup'. \n",
    "\n",
    "The next command we need to enter into our notebook is 'soup = BeautifulSoup(page.content, 'html.parser')'. The BeautifulSoup library allows us to parse structured data and access certain lines of the HTML similar to the developer tools did when we were exploring the website. The page.content attribute allows us to access the information stored in the HTML, which we can parse and pull out the specific data we're looking for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c34dc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.nytimes.com/books/best-sellers/combined-print-and-e-book-fiction/\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ddeeba",
   "metadata": {},
   "source": [
    "Now that we have the ability to parse our HTML, we need to go back to the website itself and use the developer tools to locate the information we want to pull out. We do this in steps, so first we need to find the \"id=\" line of HTML that highlights all the necessary informtion we're looking for. When we find the id containing our information, we can use the \"label\" = soup.find(id=\"Your_ID\") function to pull out all the information that is stored under the id that you specified. However, when this gets printed by itself, it isn't in a very useable format, so we use the command results.prettify() to visualize our data better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca9e2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = soup.find(id=\"site-content\")\n",
    "#print(results.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9ae349",
   "metadata": {},
   "source": [
    "Next, we go back into the website's developer tools to locate the line of HTML that highlights the specific elements that we are looking for. The wording here is a little ambigious because this element contains all the indidivual bits of data that we are trying to pull out. In this example, we're looking for a line in the developer tools that highlights the title of the book itself, the author, the publisher, and a description of the book. However, this element that we're pulling out highlights one book at a time, but we will specify the \"div\" and the \"class\" so that our program knows that we want to know all the information of the books with that \"div\" and \"class\". \n",
    "\n",
    "The code we write to achieve this depends on the previous line of code that we wrote before. So whatever we labeled the soup.find() command, will be involved in this next line of code. We use the \n",
    "\"label2\" = \"label\".find_all(\"div\", class_=\"\") function. With this command, the computer will pull out all the objects with the distinctive \"div\" and \"class\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c5a2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_elements = results.find_all(\"div\", class_=\"css-xe4cfy\")\n",
    "#for book_element in book_elements:\n",
    "#    print(book_element, end=\"\\n\"*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb419b",
   "metadata": {},
   "source": [
    "To collect the information on the book title, author, publisher, and description, we want to open an array to store these values in. Then we need to create a for loop to search for attributes within our \"label2\" (book_elements in this example). Back in the developer tools on the website, we want to find the labels that highlight each element we're looking for. In this example, we want the titles of the books, which are described by \"h3\", class_=\"css-5pe77f\". So we call the \"label2\".find() function and insert the \"h3\" and class_=\"\" attributes. We continue this process until we isolate each element that we're looking for. Then, I make a dictionary so I can clearly label my elements and append this dictionary to the data array I opened outside the for loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2938fd7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYDREAM\n",
      "by Hannah Grace\n",
      "Atria\n",
      "The third book in the Maple Hills series. A college student with writer’s block offers to tutor the captain of the hockey team.\n",
      "\n",
      "IT ENDS WITH US\n",
      "by Colleen Hoover\n",
      "Atria\n",
      "A battered wife raised in a violent home attempts to halt the cycle of abuse; the basis of the film.\n",
      "\n",
      "IT STARTS WITH US\n",
      "by Colleen Hoover\n",
      "Atria\n",
      "In the sequel to “It Ends With Us,” Lily deals with her jealous ex-husband as she reconnects with her first boyfriend.\n",
      "\n",
      "THE WOMEN\n",
      "by Kristin Hannah\n",
      "St. Martin's\n",
      "In 1965, a nursing student follows her brother to serve during the Vietnam War and returns to a divided America.\n",
      "\n",
      "A COURT OF THORNS AND ROSES\n",
      "by Sarah J. Maas\n",
      "Bloomsbury\n",
      "After killing a wolf in the woods, Feyre is taken from her home and placed inside the world of the Fae.\n",
      "\n",
      "THE HOUSEMAID\n",
      "by Freida McFadden\n",
      "Grand Central\n",
      "Troubles surface when a woman looking to make a fresh start takes a job in the home of the Winchesters.\n",
      "\n",
      "IRON FLAME\n",
      "by Rebecca Yarros\n",
      "Red Tower\n",
      "The second book in the Empyrean series. Violet Sorrengail’s next round of training might require her to betray the man she loves.\n",
      "\n",
      "DEMON COPPERHEAD\n",
      "by Barbara Kingsolver\n",
      "Harper Perennial\n",
      "Winner of a 2023 Pulitzer Prize for fiction. A reimagining of Charles Dickens’s “David Copperfield” set in the mountains of southern Appalachia.\n",
      "\n",
      "THE DARK WIVES\n",
      "by Ann Cleeves\n",
      "Minotaur\n",
      "The 11th book in the Vera Stanhope series. Vera and her team search for a missing teen who may be responsible for murder.\n",
      "\n",
      "BY ANY OTHER NAME\n",
      "by Jodi Picoult\n",
      "Ballantine\n",
      "A young woman’s play about her ancestor Emilia Bassano, who wrote Shakespeare’s works, is submitted to a festival under a male pseudonym.\n",
      "\n",
      "THE GOD OF THE WOODS\n",
      "by Liz Moore\n",
      "Riverhead\n",
      "When a 13-year-old girl disappears from an Adirondack summer camp in 1975, secrets kept by the Van Laar family emerge.\n",
      "\n",
      "A COURT OF MIST AND FURY\n",
      "by Sarah J. Maas\n",
      "Bloomsbury\n",
      "The second book in the Court of Thorns and Roses series. Feyre gains the powers of the High Fae and a greater evil emerges.\n",
      "\n",
      "THE WEDDING PEOPLE\n",
      "by Alison Espach\n",
      "Holt\n",
      "A woman who is down on her luck forms an unexpected bond with the bride at a wedding in Rhode Island.\n",
      "\n",
      "THE HOUSEMAID IS WATCHING\n",
      "by Freida McFadden\n",
      "Poisoned Pen\n",
      "The third book in the Housemaid series. Dangers lurk in a quiet neighborhood.\n",
      "\n",
      "THE HOUSEMAID'S SECRET\n",
      "by Freida McFadden\n",
      "Mobius\n",
      "The second book in the Housemaid series. The sound of crying and the appearance of blood portend misdeeds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe = []\n",
    "for book_element in book_elements:\n",
    "    title_element = book_element.find(\"h3\", class_=\"css-5pe77f\") #title\n",
    "    author_element = book_element.find(\"p\", class_=\"css-hjukut\") #author\n",
    "    publisher_element = book_element.find(\"p\", class_=\"css-heg334\") #publisher\n",
    "    description_element = book_element.find(\"p\", class_=\"css-14lubdp\") #description\n",
    "    print(title_element.text)\n",
    "    print(author_element.text)\n",
    "    print(publisher_element.text)\n",
    "    print(description_element.text)\n",
    "    dict1 = {'Title': title_element, 'Author': author_element, 'Publisher': publisher_element, \n",
    "            'Description': description_element}\n",
    "    dataframe.append(dict1)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe418643",
   "metadata": {},
   "source": [
    "To save my information as a csv file, I use the pandas.DataFrame() command to store my dataframe. Using pandas allows for easy conversion into a csv file, so the next command I use is the .to_csv(\"Your_File, index=False). However, to use the .to_csv() function, the data frame needs to be saved in a pandas extension, hence changing our original data frame to one in pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c05f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(dataframe)\n",
    "data.to_csv(\"NYT Books\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e6d59b",
   "metadata": {},
   "source": [
    "#1 Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2141cb",
   "metadata": {},
   "source": [
    "When given a csv file to read into python, we can open it in a pandas data frame using the command pd.read_csv(\"Your_File.csv\"). Using the pandas library makes our analysis of the file easier as we can pull certain elements out of the data frame. I like using the df.head() command because it prints the names of each column and the first few rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d282ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
       "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
       "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
       "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
       "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
       "\n",
       "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
       "0  M1979787155             0.0             0.0        0               0  \n",
       "1  M2044282225             0.0             0.0        0               0  \n",
       "2   C553264065             0.0             0.0        1               0  \n",
       "3    C38997010         21182.0             0.0        1               0  \n",
       "4  M1230701703             0.0             0.0        0               0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Fraud.csv.zip\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb7a3efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
       "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
       "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
       "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
       "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        1       1            1  Returning_Visitor    False    False  \n",
       "1        2       1            2  Returning_Visitor    False    False  \n",
       "2        1       9            3  Returning_Visitor    False    False  \n",
       "3        2       2            4  Returning_Visitor    False    False  \n",
       "4        3       1            4  Returning_Visitor     True    False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"online_shoppers_intention.csv\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2287eaaa",
   "metadata": {},
   "source": [
    "When dealing with a json extension, we must use the command \"with open(\"File_Name\", 'r') as x:\". The with command ensures that Python closes the file after it does what it's supposed to do in the line of code. The open command allows python to read or write directly into the json file and the 'r' command allows python to specifically read the json file. The json.load(x) command loads the data from the file as an object. Normalizing the json with json_normalize() flattens any nested data that may be in the json file. In this example, the time is most likely nested in the data, so we have a column for trans_date_trans_time so that the date and time are nested and flattened. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c3a3268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_id</th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>...</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>295780.0</td>\n",
       "      <td>12/26/2023 0:55</td>\n",
       "      <td>5.795160e+11</td>\n",
       "      <td>fraud_Bedi-Krish Pvt Ltd</td>\n",
       "      <td>None</td>\n",
       "      <td>8552.65</td>\n",
       "      <td>Baiju</td>\n",
       "      <td>Sharma</td>\n",
       "      <td>F</td>\n",
       "      <td>043, Lall Nagar, Dhule-732630</td>\n",
       "      <td>...</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>-3.661078</td>\n",
       "      <td>145.222241</td>\n",
       "      <td>691077.0</td>\n",
       "      <td>Surveyor, hydrographic</td>\n",
       "      <td>2/23/1993</td>\n",
       "      <td>-3.676868</td>\n",
       "      <td>145.213831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>825718.0</td>\n",
       "      <td>7/7/2023 7:02</td>\n",
       "      <td>4.126110e+15</td>\n",
       "      <td>None</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>9139.49</td>\n",
       "      <td>Bhavin</td>\n",
       "      <td>Roy</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.625930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comptroller</td>\n",
       "      <td>10/20/1994</td>\n",
       "      <td>-14.437954</td>\n",
       "      <td>-8.607795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.240000e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165012.0</td>\n",
       "      <td>4/25/2023 11:53</td>\n",
       "      <td>6.563210e+15</td>\n",
       "      <td>fraud_Hans-Kanda Pvt Ltd</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>7568.37</td>\n",
       "      <td>Yuvraj</td>\n",
       "      <td>Madan</td>\n",
       "      <td>M</td>\n",
       "      <td>04/41, Bawa Nagar, Khammam 816522</td>\n",
       "      <td>...</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>76.196973</td>\n",
       "      <td>102.564244</td>\n",
       "      <td>380244.0</td>\n",
       "      <td>Probation officer</td>\n",
       "      <td>10/18/1963</td>\n",
       "      <td>76.214025</td>\n",
       "      <td>102.567219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.610000e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5/28/2023 18:26</td>\n",
       "      <td>3.531340e+15</td>\n",
       "      <td>None</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>9074.00</td>\n",
       "      <td>Drishya</td>\n",
       "      <td>Bumb</td>\n",
       "      <td>F</td>\n",
       "      <td>53/26, Chana Ganj, Varanasi 329560</td>\n",
       "      <td>...</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>27.840855</td>\n",
       "      <td>93.934433</td>\n",
       "      <td>440893.0</td>\n",
       "      <td>None</td>\n",
       "      <td>4/27/1996</td>\n",
       "      <td>27.838502</td>\n",
       "      <td>93.950223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.190000e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>742125.0</td>\n",
       "      <td>2/15/2023 18:55</td>\n",
       "      <td>4.800550e+12</td>\n",
       "      <td>fraud_Agate, Varkey and Luthra Pvt Ltd</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>5056.81</td>\n",
       "      <td>None</td>\n",
       "      <td>Lal</td>\n",
       "      <td>M</td>\n",
       "      <td>43/32, Yohannan Zila, Udaipur-067444</td>\n",
       "      <td>...</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>81.974419</td>\n",
       "      <td>71.656847</td>\n",
       "      <td>308606.0</td>\n",
       "      <td>Chiropodist</td>\n",
       "      <td>1/19/1994</td>\n",
       "      <td>81.959219</td>\n",
       "      <td>71.668432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.210000e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trans_id trans_date_trans_time        cc_num  \\\n",
       "0  295780.0       12/26/2023 0:55  5.795160e+11   \n",
       "1  825718.0         7/7/2023 7:02  4.126110e+15   \n",
       "2  165012.0       4/25/2023 11:53  6.563210e+15   \n",
       "3       NaN       5/28/2023 18:26  3.531340e+15   \n",
       "4  742125.0       2/15/2023 18:55  4.800550e+12   \n",
       "\n",
       "                                 merchant       category      amt    first  \\\n",
       "0                fraud_Bedi-Krish Pvt Ltd           None  8552.65    Baiju   \n",
       "1                                    None  entertainment  9139.49   Bhavin   \n",
       "2                fraud_Hans-Kanda Pvt Ltd  entertainment  7568.37  Yuvraj    \n",
       "3                                    None  entertainment  9074.00  Drishya   \n",
       "4  fraud_Agate, Varkey and Luthra Pvt Ltd  entertainment  5056.81     None   \n",
       "\n",
       "     last gender                                street  ...         state  \\\n",
       "0  Sharma      F         043, Lall Nagar, Dhule-732630  ...     Rajasthan   \n",
       "1     Roy      M                                  None  ...     Meghalaya   \n",
       "2   Madan      M     04/41, Bawa Nagar, Khammam 816522  ...       Mizoram   \n",
       "3    Bumb      F    53/26, Chana Ganj, Varanasi 329560  ...  Chhattisgarh   \n",
       "4     Lal      M  43/32, Yohannan Zila, Udaipur-067444  ...     Jharkhand   \n",
       "\n",
       "         lat        long  city_pop                     job         dob  \\\n",
       "0  -3.661078  145.222241  691077.0  Surveyor, hydrographic   2/23/1993   \n",
       "1        NaN   -8.625930       NaN             Comptroller  10/20/1994   \n",
       "2  76.196973  102.564244  380244.0       Probation officer  10/18/1963   \n",
       "3  27.840855   93.934433  440893.0                    None   4/27/1996   \n",
       "4  81.974419   71.656847  308606.0             Chiropodist   1/19/1994   \n",
       "\n",
       "   merch_lat  merch_long  is_fraud   customer_id  \n",
       "0  -3.676868  145.213831       0.0           NaN  \n",
       "1 -14.437954   -8.607795       NaN  6.240000e+18  \n",
       "2  76.214025  102.567219       0.0 -2.610000e+18  \n",
       "3  27.838502   93.950223       0.0  2.190000e+18  \n",
       "4  81.959219   71.668432       0.0 -5.210000e+18  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Augmented_IndiaTransactMultiFacet2024.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Flatten the JSON\n",
    "df3 = json_normalize(data)\n",
    "\n",
    "df3.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ab6e95",
   "metadata": {},
   "source": [
    "For files that are excel tables, or have the xlsx. extension, I find that it is easier to upload the file in excel to visualize the information you want saved. In this example, the excel sheet had multiple tabs to choose from and I wanted to save the transactions tab, so I saved it as a csv to easily read into python using the steps I talked about above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fcdb0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>online_order</th>\n",
       "      <th>order_status</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_line</th>\n",
       "      <th>product_class</th>\n",
       "      <th>product_size</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 246</th>\n",
       "      <th>Unnamed: 247</th>\n",
       "      <th>Unnamed: 248</th>\n",
       "      <th>Unnamed: 249</th>\n",
       "      <th>Unnamed: 250</th>\n",
       "      <th>Unnamed: 251</th>\n",
       "      <th>Unnamed: 252</th>\n",
       "      <th>Unnamed: 253</th>\n",
       "      <th>Unnamed: 254</th>\n",
       "      <th>Unnamed: 255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2950</td>\n",
       "      <td>25/02/2017</td>\n",
       "      <td>False</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Solex</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3120</td>\n",
       "      <td>21/05/2017</td>\n",
       "      <td>True</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Trek Bicycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>large</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>402</td>\n",
       "      <td>16/10/2017</td>\n",
       "      <td>False</td>\n",
       "      <td>Approved</td>\n",
       "      <td>OHM Cycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>3135</td>\n",
       "      <td>31/08/2017</td>\n",
       "      <td>False</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Norco Bicycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>787</td>\n",
       "      <td>01/10/2017</td>\n",
       "      <td>True</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Giant Bicycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>large</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id  product_id  customer_id transaction_date online_order  \\\n",
       "0               1           2         2950       25/02/2017        False   \n",
       "1               2           3         3120       21/05/2017         True   \n",
       "2               3          37          402       16/10/2017        False   \n",
       "3               4          88         3135       31/08/2017        False   \n",
       "4               5          78          787       01/10/2017         True   \n",
       "\n",
       "  order_status           brand product_line product_class product_size  ...  \\\n",
       "0     Approved           Solex     Standard        medium       medium  ...   \n",
       "1     Approved   Trek Bicycles     Standard        medium        large  ...   \n",
       "2     Approved      OHM Cycles     Standard           low       medium  ...   \n",
       "3     Approved  Norco Bicycles     Standard        medium       medium  ...   \n",
       "4     Approved  Giant Bicycles     Standard        medium        large  ...   \n",
       "\n",
       "   Unnamed: 246 Unnamed: 247  Unnamed: 248  Unnamed: 249  Unnamed: 250  \\\n",
       "0           NaN          NaN           NaN           NaN           NaN   \n",
       "1           NaN          NaN           NaN           NaN           NaN   \n",
       "2           NaN          NaN           NaN           NaN           NaN   \n",
       "3           NaN          NaN           NaN           NaN           NaN   \n",
       "4           NaN          NaN           NaN           NaN           NaN   \n",
       "\n",
       "   Unnamed: 251  Unnamed: 252  Unnamed: 253  Unnamed: 254  Unnamed: 255  \n",
       "0           NaN           NaN           NaN           NaN           NaN  \n",
       "1           NaN           NaN           NaN           NaN           NaN  \n",
       "2           NaN           NaN           NaN           NaN           NaN  \n",
       "3           NaN           NaN           NaN           NaN           NaN  \n",
       "4           NaN           NaN           NaN           NaN           NaN  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#originally a xlsx extension \n",
    "df4 = pd.read_csv('KPMG_VI_New_raw_data_update_final(Transactions).csv')\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdd2e86",
   "metadata": {},
   "source": [
    "When satisfied with the information obtained, I create a dictionary to clearly name the categories I'm keeping from the data. To attach the new name of my data to the column I am extracting from my files, I call the data frame I read in and its specific column name, such as df2['ProductRelated']. So now my dictionary has names to accurately describe each column and the information from that column in the dataframe. To store and save this dictionary, I want to store it in a pandas dataframe, called newdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2456f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'Online Shopper Intention: Product Related': df2['ProductRelated'], \n",
    "        'Online Shopper Intention: Product Related Duration': df2['ProductRelated_Duration'], \n",
    "        'Online Shopper Intention by Region': df2['Region'],\n",
    "        'Balance Before Fraud':df['oldbalanceOrg'], \n",
    "        'Fraud Amount': df['isFraud'], \n",
    "        'Transaction Date and Time': df3['trans_date_trans_time'], \n",
    "        'Job of Purchaser': df3['job'],\n",
    "        'Gender of Purchaser': df3['gender'],\n",
    "        'Purchase Category': df3['category'],\n",
    "        'List Price of Product': df4['list_price']}\n",
    "newdf = pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d051b591",
   "metadata": {},
   "source": [
    "Now that my dictionary is in a pandas dataframe, I can easily save my information to a csv by using the .to_csv('File_Name', index=False). We don't want the index because our columns already have names and don't need further identifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ed7879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.to_csv('combined_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ecca3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
